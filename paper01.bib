@inproceedings{michaud2016best,
  title        = {Best-offset hardware prefetching},
  author       = {Michaud, Pierre},
  booktitle    = {2016 IEEE International Symposium on High Performance Computer Architecture (HPCA)},
  pages        = {469--480},
  year         = {2016},
  organization = {IEEE}
}
@inproceedings{michaud2015best,
  title     = {A best-offset prefetcher},
  author    = {Michaud, Pierre},
  booktitle = {2nd Data Prefetching Championship},
  year      = {2015}
}
@inproceedings{kim2016path,
  title        = {Path confidence based lookahead prefetching},
  author       = {Kim, Jinchun and Pugsley, Seth H and Gratz, Paul V and Reddy, AL Narasimha and Wilkerson, Chris and Chishti, Zeshan},
  booktitle    = {2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)},
  pages        = {1--12},
  year         = {2016},
  organization = {IEEE}
}
@article{kim2015lookahead,
  title   = {Lookahead prefetching with signature path},
  author  = {Kim, ALNR Jinchun and Gratz, Paul V and Reddy, AL Narasimha},
  journal = {The 2nd Data Prefetching Championship (DPC2)},
  year    = {2015}
}
@inproceedings{augury,
  title        = {Augury: Using Data Memory-Dependent Prefetchers to Leak Data at Rest},
  author       = {Jose Rodrigo Sanchez Vicarte and Michael Flanders and
                  Riccardo Paccagnella and Grant Garrett-Grossman and
                  Adam Morrison and Christopher W. Fletcher and David Kohlbrenner },
  booktitle    = {IEEE Symposium on Security and Privacy (SP)},
  year         = {2022},
  organization = {IEEE Computer Society}
}
@inproceedings{vavouliotis2022page,
  title        = {Page Size Aware Cache Prefetching},
  author       = {Vavouliotis, Georgios and Chacon, Gino and Alvarez, Lluc and Gratz, Paul V and Jim{\'e}nez, Daniel A and Casas, Marc},
  booktitle    = {2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO)},
  pages        = {956--974},
  year         = {2022},
  organization = {IEEE}
}
@misc{umich,
  title = {Making Address-Correlated Prefetching Practical},
  url   = {https://web.eecs.umich.edu/~twenisch/papers/ieee-micro10.pdf}
}
@inproceedings{10.1145,
  author    = {Bhatia, Eshan and Chacon, Gino and Pugsley, Seth and Teran, Elvira and Gratz, Paul V.},
  title     = {Perceptron-Based Prefetch Filtering},
  year      = {2019},
  isbn      = {9781450366694},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  abstract  = {Hardware prefetching is an effective technique for hiding cache miss latencies in modern processor designs. Prefetcher performance can be characterized by two main metrics that are generally at odds with one another: coverage, the fraction of baseline cache misses which the prefetcher brings into the cache; and accuracy, the fraction of prefetches which are ultimately used. An overly aggressive prefetcher may improve coverage at the cost of reduced accuracy. Thus, performance may be harmed by this over-aggressiveness because many resources are wasted, including cache capacity and bandwidth. An ideal prefetcher would have both high coverage and accuracy.In this paper, we introduce Perceptron-based Prefetch Filtering (PPF) as a way to increase the coverage of the prefetches generated by an underlying prefetcher without negatively impacting accuracy. PPF enables more aggressive tuning of the underlying prefetcher, leading to increased coverage by filtering out the growing numbers of inaccurate prefetches such an aggressive tuning implies. We also explore a range of features to use to train PPF's perceptron layer to identify inaccurate prefetches. PPF improves performance on a memory-intensive subset of the SPEC CPU 2017 benchmarks by 3.78% for a single-core configuration, and by 11.4% for a 4-core configuration, compared to the underlying prefetcher alone.},
  booktitle = {Proceedings of the 46th International Symposium on Computer Architecture},
  pages     = {1â€“13},
  numpages  = {13},
  location  = {Phoenix, Arizona},
  series    = {ISCA '19}
}

